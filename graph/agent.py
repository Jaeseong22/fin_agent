from dotenv import load_dotenv
from langchain_teddynote import logging
load_dotenv()
logging.langsmith("fin_agent")

import os
import json
from typing import Literal, Optional
from schema import State, Task1, Task2, Task3
from utils import (parse_tool_json,
                    check_task1,
                    check_task2, 
                    check_task3, 
                    ENGINE, 
                    run_task1_query, 
                    run_task2_query, 
                    run_task3_query,
                    rewrite_query_with_human_feedback,
                    apply_ambiguity_resolution,
                    _pick_best_result,
                    _r_task1_market_comparison,
                    _r_task1_market_index_comparison,
                    _r_task1_metric_rank,
                    _r_task1_simple_lookup,
                    _r_task1_stock_comparison,
                    _r_task1_stock_rank,
                    _r_task1_stock_to_market_ratio,
                    _r_task2,
                    _r_task3)
from langchain_core.messages import HumanMessage, AIMessage
from langchain_openai import ChatOpenAI
from langgraph.types import Command, interrupt
from langgraph.graph import END
from langsmith import Client

# ë§¨ ìœ„ ê·¼ì²˜ì— ìƒìˆ˜ ì¶”ê°€
DEFAULT_Q = "ì›í•˜ì‹œëŠ” ì¡°ê±´ì„ ë” êµ¬ì²´ì ìœ¼ë¡œ ì•Œë ¤ì£¼ì„¸ìš”. ì˜ˆ) ê¸°ê°„, ì‹œì¥(KOSPI/KOSDAQ), ì‹ í˜¸ ì¢…ë¥˜ ë“±"

client = Client(api_key=os.environ.get("LANGSMITH_API_KEY"))
task_classifier_prompt = client.pull_prompt("task_classifier", include_model=True)

llm = ChatOpenAI(temperature=0.2, 
                 model="gpt-4o-mini",)

def task_classifier(state: State) -> Command[Literal["query_parsing", "ask_human","chatbot"]]:
    messages = state["messages"][-1]
    chain = task_classifier_prompt
    result = chain.invoke({"messages" : messages.content})
    tool_calls = result.additional_kwargs.get("tool_calls", [])
    if not tool_calls:
        # ë¶„ë¥˜ ì‹¤íŒ¨ ì‹œ ì±—ë´‡ìœ¼ë¡œ
        return Command(goto="chatbot")

    try:
        arguments_str = tool_calls[0]["function"]["arguments"]
        arguments = json.loads(arguments_str)
        task = arguments.get("Task")  # "Task1"|"Task2"|"Task3"|"Chatbot"
    except Exception as e:
        print("task parse error:", e)
        return Command(goto="chatbot")

    print("Detected task:", task)

    match task:
        case "Task1":
            task_instance = Task1(date="", market=None, clauses=[])
            return Command(goto="query_parsing",
                           update={"task": task_instance, "task_name": task})
        case "Task2":
            task_instance = Task2(date="", market=None, clauses=[])
            return Command(goto="query_parsing",
                           update={"task": task_instance, "task_name": task})
        case "Task3":
            task_instance = Task3(company_name=None, market=None,
                                  period_start="", period_end="",
                                  signal_type=[], mode="list")
            return Command(goto="query_parsing",
                           update={"task": task_instance, "task_name": task})
        case "Task4":
            return Command(
                goto="ask_human",
                update={
                    "ask_human": True,
                    "human_question": "ì–´ë–¤ ê´€ì ì˜ ê¸ˆìœµ ì§ˆë¬¸ì¸ì§€ êµ¬ì²´í™”í•´ ì£¼ì„¸ìš”. ì˜ˆ) ë‚ ì§œ/ê¸°ê°„, ì‹œì¥(KOSPI/KOSDAQ), ì „ìˆ˜ê²€ìƒ‰ ì—¬ë¶€, ì‹ í˜¸(ì˜ˆ: ì´ë™í‰ê· /RSI/ê±°ë˜ëŸ‰ ìŠ¤íŒŒì´í¬) ë“±"
                }
            ) 
        case "Chatbot":
            return Command(goto="chatbot")
        
        case _:
            return Command(goto="chatbot")
       
def chatbot(state: State) -> Command[Literal["llm_answer"]]:
    messages = state["messages"][-1]
    result = llm.invoke(messages)
    return Command(goto="llm_answer",
                   update={"answer": [result.content]})

def query_parsing(state: State) -> Command[Literal["db_check", "ask_human"]]:
    messages = state["messages"][-1]
    task = state["task_name"]
    task_obj = state["task"]

    match task:
        case "Task1":
            parsing_prompt = client.pull_prompt("parsing_task1", include_model=True)
            result = parsing_prompt.invoke({"messages" : messages.content})
            data = parse_tool_json(result)
            if not data:
                return Command(goto="ask_human")
            payload = data.get("Task1", data)
            try:
                updated_task = task_obj.model_copy(update=payload)
            except Exception as e:
                print("parsing validation error:", e)
                return Command(goto="ask_human")
            return Command(goto="db_check", update={"task": updated_task})
        
        case "Task2":
            parsing_prompt = client.pull_prompt("parsing_task2", include_model=True)
            result = parsing_prompt.invoke({"messages" : messages.content})
            data = parse_tool_json(result)
            if not data:
                return Command(goto="ask_human")
            payload = data.get("Task2", data)
            try:
                updated_task = task_obj.model_copy(update=payload)
            except Exception as e:
                print("parsing validation error:", e)
                return Command(goto="ask_human")
            return Command(goto="db_check", update={"task": updated_task})
            
        case "Task3":
            parsing_prompt = client.pull_prompt("parsing_task3", include_model=True)
            result = parsing_prompt.invoke({"messages" : messages.content})
            data = parse_tool_json(result)
            if not data:
                return Command(goto="ask_human")
            payload = data.get("Task3", data)
            try:
                updated_task = task_obj.model_copy(update=payload)
            except Exception as e:
                print("parsing validation error:", e)
                return Command(goto="ask_human")
            return Command(goto="db_check", update={"task": updated_task})
        
        case _:
            return Command(goto="ask_human")
        
def db_check(state: State) -> Command[Literal["task1", "task2", "task3", "ambiguity_handler"]]:
    task_class = state["task_name"]
    task_obj   = state["task"]

    match task_class:
        case "Task1":
            if not check_task1(task_obj):
                return Command(goto="ambiguity_handler")
            return Command(goto="task1")

        case "Task2":
            if not check_task2(task_obj):
                return Command(goto="ambiguity_handler")
            return Command(goto="task2")

        case "Task3":
            if not check_task3(task_obj):
                return Command(goto="ambiguity_handler")
            return Command(goto="task3")

        case _:
            return Command(goto="ask_human", update={"ask_human": True})
        
def task1(state: State) -> Command[Literal["llm_answer"]]:
    task_obj = state["task"]
    result = run_task1_query(task_obj, ENGINE)
    return Command(goto="llm_answer", update={"task1_result": result})

def task2(state: State) -> Command[Literal["llm_answer"]]:
    task_obj = state["task"]
    result = run_task2_query(task_obj, ENGINE)
    return Command(goto="llm_answer", update={"task2_result": result})

def task3(state: State) -> Command[Literal["llm_answer"]]:
    task_obj = state["task"]
    result = run_task3_query(task_obj, ENGINE)
    return Command(goto="llm_answer", update={"task3_result": result})


def ask_human(state: State) -> Command[Literal["task_classifier"]]:
    """
    1) ì§ˆë¬¸ì„ ë©”ì‹œì§€ì— ë‚¨ê¸°ê³ 
    2) interrupt()ë¡œ ì‹¤í–‰ì„ ë©ˆì¶° ì‚¬ìš©ì ì…ë ¥ì„ ê¸°ë‹¤ë¦¼
    3) ì¬ê°œ ì‹œ ì‚¬ëŒì˜ ë‹µë³€ì„ ê¸°ì¡´ ì§ˆì˜ì™€ ë³‘í•© â†’ task_classifierë¡œ ì í”„
    """
    q = state.get("human_question")

    # ì§ˆë¬¸ì„ ëŒ€í™” íë¦„ì— ë‚¨ê²¨ë‘”ë‹¤
    messages = state["messages"] + [AIMessage(content=q)]

    # ğŸ”´ ì—¬ê¸°ì„œ ê·¸ë˜í”„ ì‹¤í–‰ 'ì •ì§€' â†’ ë™ì¼ threadë¡œ HumanMessageê°€ ë„ì°©í•˜ë©´ ë‹¤ìŒ ì¤„ë¶€í„° ì¬ê°œ
    human_reply: HumanMessage = interrupt(
        value={"reason": "need_more_info", "question": q}
    )

    # ì‚¬ìš©ì ë‹µë³€ì„ messagesì— ë¶™ì¸ë‹¤
    resumed_state = dict(state)
    resumed_state["messages"] = messages + [human_reply]
    resumed_state["ask_human"] = False
    resumed_state["human_question"] = q

    # ê¸°ì¡´ ë³‘í•© ìœ í‹¸ ì¬ì‚¬ìš© (ì›ì§ˆì˜ + ì¶”ê°€ ì…ë ¥ì„ í•©ì¹¨)
    merged = rewrite_query_with_human_feedback(resumed_state)

    # ë¶„ë¥˜ ë‹¨ê³„ë¡œ ë˜ëŒë¦¼
    return Command(goto="task_classifier", update=merged)

def ambiguity_handler(state: State) -> Command[Literal["task1", "task2", "task3", "ask_human"]]:
    last = state["messages"][-1]
    query_text = getattr(last, "content", "")

    upd = apply_ambiguity_resolution(query_text)
    new_state = {"normalized_query": upd.get("normalized_query")}
    if "clarified_fields" in upd:
        prev = state.get("clarified_fields") or {}
        merged = {**prev, **upd["clarified_fields"]}
        new_state["clarified_fields"] = merged
    if "term_hits" in upd:
        new_state["term_hits"] = upd["term_hits"]
    
    task_name = state.get("task_name")
    task_obj  = state.get("task")
    
    def _has(v): return v is not None and v != "" and v != []

    if task_name == "Task3":
        # ìµœì†Œ: ê¸°ê°„ + ì‹ í˜¸ í‘œí˜„(ì •ê·œí™”ëœ ë¬¸ì¥ì— íŒ¨í„´/ì§€í‘œ ë‹¨ì–´ê°€ ë“¤ì–´ê°€ê±°ë‚˜ term_hits ì¡´ì¬)
        has_period = _has(getattr(task_obj, "period_start", None)) or _has(getattr(task_obj, "period_end", None))
        has_signal = bool(new_state.get("term_hits"))
        if has_period and has_signal:
            # ë°”ë¡œ task3 ì‹¤í–‰
            return Command(goto="task3", update=new_state)
        else:
            # ì‚¬ëŒì—ê²Œ ë¬¼ì–´ë³¼ ì§ˆë¬¸ ì œì•ˆ
            q = []
            if not has_period:
                q.append("ê¸°ê°„(ì˜ˆ: 2024-01-01~2024-12-31)")
            if not has_signal:
                q.append("ì‹ í˜¸ ì¢…ë¥˜(ì˜ˆ: RSI ê³¼ë§¤ìˆ˜/ë³¼ë¦°ì € ìƒë‹¨ í„°ì¹˜/ê³¨ë“ í¬ë¡œìŠ¤ ë“±)")
            ask = "ë¶„ì„ì„ ìœ„í•´ ì¶”ê°€ ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤. " + " / ".join(q) + " ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”."
            return Command(goto="ask_human", update={**new_state, "human_question": ask, "ask_human": False})

    elif task_name == "Task2":
        has_date = _has(getattr(task_obj, "date", None))
        has_clauses = _has(getattr(task_obj, "clauses", None))
        if has_date and has_clauses:
            return Command(goto="task2", update=new_state)
        else:
            ask = "ì¡°ê±´ ê²€ìƒ‰ì„ ìœ„í•´ ë‚ ì§œì™€ ì¡°ê±´(ë“±ë½ë¥ /ê±°ë˜ëŸ‰ ë“±)ì„ êµ¬ì²´í™”í•´ ì£¼ì„¸ìš”. ì˜ˆ: 2025-06-13, ë“±ë½ë¥  â‰¥ 7%, ê±°ë˜ëŸ‰ ì „ì¼ ëŒ€ë¹„ â‰¥ 300%."
            return Command(goto="ask_human", update={**new_state, "human_question": ask, "ask_human": False})

    elif task_name == "Task1":
        has_date = _has(getattr(task_obj, "date", None))
        if has_date:
            return Command(goto="task1", update=new_state)
        else:
            ask = "ì¡°íšŒí•  ë‚ ì§œ(ë˜ëŠ” ê¸°ê°„)ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”. ì˜ˆ: 2025-01-21."
            return Command(goto="ask_human", update={**new_state, "human_question": ask, "ask_human": False})

    # í˜¹ì‹œ ëª¨ë¥´ë©´ ì‚¬ëŒì—ê²Œ
    return Command(goto="ask_human", update={**new_state, "human_question": "ì›í•˜ì‹œëŠ” ì¡°ê±´ì„ ì¡°ê¸ˆ ë” êµ¬ì²´ì ìœ¼ë¡œ ì•Œë ¤ì£¼ì„¸ìš”.", "ask_human": False})

def llm_answer(state: State) -> Command[END]:
    """
    - stateì—ì„œ ìµœì‹  ê²°ê³¼(dict)ë¥¼ ê³ ë¥´ê³ 
    - ìœ í˜•ë³„ ìì—°ì–´ ìš”ì•½ ìƒì„±
    - ENDë¡œ ì¢…ë£Œ
    """
    result = _pick_best_result(state or {})
    if not isinstance(result, dict):
        # chatbot ê²½ë¡œì—ì„œ ì´ë¯¸ answerê°€ ë“¤ì–´ì˜¨ ê²½ìš°ëŠ” ë°”ë¡œ ì¢…ë£Œ
        if state.get("answer"):
            return Command(goto=END)
        return Command(goto=END, update={"answer": ["ê²°ê³¼ê°€ ì—†ì–´ ë‹µë³€ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."]})

    status = result.get("status", "ok")
    if status != "ok":
        reason = result.get("reason") or "ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        return Command(goto=END, update={"answer": [f"ìš”ì²­ì„ ì²˜ë¦¬í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì‚¬ìœ : {reason}"], "result": result})

    rtype = result.get("type")
    if rtype in {
        "metric_rank", "market_comparison", "stock_comparison",
        "simple_lookup", "stock_rank", "stock_to_market_ratio",
        "market_index_comparison"
    }:
        if rtype == "metric_rank":
            answer = _r_task1_metric_rank(result)
        elif rtype == "market_comparison":
            answer = _r_task1_market_comparison(result)
        elif rtype == "stock_comparison":
            answer = _r_task1_stock_comparison(result)
        elif rtype == "simple_lookup":
            answer = _r_task1_simple_lookup(result)
        elif rtype == "stock_rank":
            answer = _r_task1_stock_rank(result)
        elif rtype == "stock_to_market_ratio":
            answer = _r_task1_stock_to_market_ratio(result)
        elif rtype == "market_index_comparison":
            answer = _r_task1_market_index_comparison(result)
        else:
            answer = "ì•Œ ìˆ˜ ì—†ëŠ” Task1 ê²°ê³¼ ìœ í˜•ì…ë‹ˆë‹¤."
    else:
        if "applied_clauses" in result:       # Task2
            answer = _r_task2(result)
        elif result.get("period_start") and result.get("period_end"):  # Task3
            answer = _r_task3(result)
        else:
            rows = result.get("rows", [])
            answer = f"ê²°ê³¼ {len(rows)}ê±´ì´ ì¡°íšŒë˜ì—ˆìŠµë‹ˆë‹¤."
            if rows:
                sample = rows[:5]
                bullets = [f"  - {s.get('trade_date','')} {s.get('name','')}" for s in sample]
                answer += "\nì˜ˆì‹œ:\n" + "\n".join(bullets)

    nq = state.get("normalized_query")
    if nq:
        answer = f"ì§ˆì˜: {nq}\n\n" + answer

    return Command(goto=END, update={"answer": [answer], "result": result})